{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not build wheels for chroma-hnswlib, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
    "!pip install -qqq openai\n",
    "!pip install -Uqqq chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "import langchain\n",
    "# import chromadb\n",
    "import transformers\n",
    "import openai\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"config.json\")\n",
    "config = json.load(f)\n",
    "os.environ[\"OPENAI_API_KEY\"] = config[\"key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /meta-llama/Llama-2-7b-chat-hf/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:root:Tokenizer loaded with model meta-llama/Llama-2-7b-chat-hf\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /meta-llama/Llama-2-7b-chat-hf/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /meta-llama/Llama-2-7b-chat-hf/resolve/main/model-00001-of-00002.safetensors HTTP/1.1\" 302 0\n",
      "DEBUG:filelock:Attempting to acquire lock 5306425008 on /Users/taylor/.cache/huggingface/hub/.locks/models--meta-llama--Llama-2-7b-chat-hf/66dec18c9f1705b9387d62f8485f4e7d871ca388718786737ed3c72dbfaac9fb.lock\n",
      "DEBUG:filelock:Lock 5306425008 acquired on /Users/taylor/.cache/huggingface/hub/.locks/models--meta-llama--Llama-2-7b-chat-hf/66dec18c9f1705b9387d62f8485f4e7d871ca388718786737ed3c72dbfaac9fb.lock\n",
      "/Users/taylor/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.58 MB. The target location /Users/taylor/.cache/huggingface/hub only has 8271.43 MB free disk space.\n",
      "  warnings.warn(\n",
      "/Users/taylor/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1003: UserWarning: Not enough free disk space to download the file. The expected file size is: 9976.58 MB. The target location /Users/taylor/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/blobs only has 8271.43 MB free disk space.\n",
      "  warnings.warn(\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: cdn-lfs.huggingface.co\n",
      "DEBUG:urllib3.connectionpool:https://cdn-lfs.huggingface.co:443 \"GET /repos/34/fa/34fa0aabe98acb3ff4f32374017550dedfae6db05863872cb0cdda960f59a928/66dec18c9f1705b9387d62f8485f4e7d871ca388718786737ed3c72dbfaac9fb?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1714078403&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxNDA3ODQwM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zNC9mYS8zNGZhMGFhYmU5OGFjYjNmZjRmMzIzNzQwMTc1NTBkZWRmYWU2ZGIwNTg2Mzg3MmNiMGNkZGE5NjBmNTlhOTI4LzY2ZGVjMThjOWYxNzA1YjkzODdkNjJmODQ4NWY0ZTdkODcxY2EzODg3MTg3ODY3MzdlZDNjNzJkYmZhYWM5ZmI~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=z0WpC7F3qtmvRv9noMT2DEHiS2ChHvHh5n6TRiFdkoUQMUfIS2jvmB0MyayFkvls5~XxoXdtTwKT-nTvm9eJfLKMPgukel2XUvxmJOtubsQ2W9tI2VTqFTLiKpUoA7LQzqcZVw~I69XZQaANX0nMwDxp9Nn4cwrCYpbksTu3PmcRAgk4yI1No7cBPtD35EcCz8lwdi-OjNBkzayHbPMM56ltf4uj4SWAMXAjpzUZGAAU2nNV~o6bx4uppL2WV0jQ5EcP~qVpqsTAXDg4DBgD0~LDgCNFay8tFmvWmdZTyGDfb2ruKdWdMTMgzkylso6ug1G1crwwhN9Dp-tTB-TRfQ__&Key-Pair-Id=KVTP0A1DKRTAX HTTP/1.1\" 200 9976576152\n",
      "DEBUG:filelock:Attempting to release lock 5306425008 on /Users/taylor/.cache/huggingface/hub/.locks/models--meta-llama--Llama-2-7b-chat-hf/66dec18c9f1705b9387d62f8485f4e7d871ca388718786737ed3c72dbfaac9fb.lock\n",
      "DEBUG:filelock:Lock 5306425008 released on /Users/taylor/.cache/huggingface/hub/.locks/models--meta-llama--Llama-2-7b-chat-hf/66dec18c9f1705b9387d62f8485f4e7d871ca388718786737ed3c72dbfaac9fb.lock\n",
      "Downloading shards:   0%|          | 0/2 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m      3\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mTokenizer loaded with model \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, model)\n\u001b[0;32m----> 5\u001b[0m pipeline \u001b[39m=\u001b[39m transformers\u001b[39m.\u001b[39;49mpipeline(\n\u001b[1;32m      6\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mtext-generation\u001b[39;49m\u001b[39m\"\u001b[39;49m,  \u001b[39m# task\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      8\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m      9\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mbfloat16,\n\u001b[1;32m     10\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     11\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     14\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     eos_token_id\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49meos_token_id\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m logging\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mPipeline created with model \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, model)\n\u001b[1;32m     20\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mHuggingFacePipeline\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:906\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    905\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 906\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    907\u001b[0m         model,\n\u001b[1;32m    908\u001b[0m         model_classes\u001b[39m=\u001b[39;49mmodel_classes,\n\u001b[1;32m    909\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    910\u001b[0m         framework\u001b[39m=\u001b[39;49mframework,\n\u001b[1;32m    911\u001b[0m         task\u001b[39m=\u001b[39;49mtask,\n\u001b[1;32m    912\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[1;32m    913\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m    914\u001b[0m     )\n\u001b[1;32m    916\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    917\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:283\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    284\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    285\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3436\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3434\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3435\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3436\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   3437\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3438\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3439\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   3440\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   3441\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   3442\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   3443\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   3444\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   3445\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   3446\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   3447\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   3448\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   3449\u001b[0m     )\n\u001b[1;32m   3451\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3452\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3453\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(resolved_archive_file, \u001b[39mstr\u001b[39m)\n\u001b[1;32m   3454\u001b[0m     \u001b[39mand\u001b[39;00m resolved_archive_file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.safetensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3455\u001b[0m ):\n\u001b[1;32m   3456\u001b[0m     \u001b[39mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:1038\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1036\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   1039\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1040\u001b[0m             shard_filename,\n\u001b[1;32m   1041\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1042\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1043\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1044\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1045\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1046\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1047\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1048\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1049\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   1050\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[1;32m   1051\u001b[0m         )\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    396\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    399\u001b[0m         path_or_repo_id,\n\u001b[1;32m    400\u001b[0m         filename,\n\u001b[1;32m    401\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    402\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    403\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    404\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    405\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    406\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    407\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    408\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    409\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    410\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    411\u001b[0m     )\n\u001b[1;32m    412\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    413\u001b[0m     resolved_file \u001b[39m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1492\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[0;32m-> 1492\u001b[0m     http_get(\n\u001b[1;32m   1493\u001b[0m         url_to_download,\n\u001b[1;32m   1494\u001b[0m         temp_file,\n\u001b[1;32m   1495\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1496\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m   1497\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1498\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[1;32m   1499\u001b[0m         displayed_filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[1;32m   1500\u001b[0m     )\n\u001b[1;32m   1502\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1503\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:535\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    533\u001b[0m new_resume_size \u001b[39m=\u001b[39m resume_size\n\u001b[1;32m    534\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m r\u001b[39m.\u001b[39;49miter_content(chunk_size\u001b[39m=\u001b[39;49mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    536\u001b[0m         \u001b[39mif\u001b[39;49;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    537\u001b[0m             progress\u001b[39m.\u001b[39;49mupdate(\u001b[39mlen\u001b[39;49m(chunk))\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/urllib3/response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m   1045\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m   1046\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/urllib3/response.py:935\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m amt:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer\u001b[39m.\u001b[39mget(amt)\n\u001b[0;32m--> 935\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[1;32m    937\u001b[0m flush_decoder \u001b[39m=\u001b[39m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data)\n\u001b[1;32m    939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    861\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 862\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt, read1\u001b[39m=\u001b[39;49mread1) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    863\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         \u001b[39m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    871\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Desktop/Grade 12/ATCS/atcs-final/.venv/lib/python3.12/site-packages/urllib3/response.py:845\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread1(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread1()\n\u001b[1;32m    843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 845\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:702\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Read up to len(b) bytes into the writable buffer *b* and return\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39mthe number of bytes read.  If the socket is non-blocking and no bytes\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39mare available, None is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39mwas shutdown at the other end.\u001b[39;00m\n\u001b[1;32m    700\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkClosed()\n\u001b[0;32m--> 702\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_checkReadable()\n\u001b[1;32m    703\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred:\n\u001b[1;32m    704\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot read from timed out object\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "logging.debug(\"Tokenizer loaded with model %s\", model)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",  # task\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "logging.debug(\"Pipeline created with model %s\", model)\n",
    "\n",
    "class HuggingFacePipeline:\n",
    "    def __init__(self, pipeline, model_kwargs):\n",
    "        self.pipeline = pipeline\n",
    "        self.model_kwargs = model_kwargs\n",
    "        logging.debug(\"HuggingFacePipeline initialized with model_kwargs: %s\", model_kwargs)\n",
    "\n",
    "# LLM initialized in HuggingFace Pipeline wrapper\n",
    "llm = HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature': 0})\n",
    "logging.debug(\"LLM initialized with temperature set to 0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
