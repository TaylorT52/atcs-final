{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mixedbread_ai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m RetrievalQA\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprompts\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmixedbread_ai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m MixedbreadAI\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m embedding_functions\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mixedbread_ai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "import langchain\n",
    "import chromadb\n",
    "import transformers\n",
    "import openai\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from mixedbread_ai.client import MixedbreadAI\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config data\n",
    "f = open('config.json')\n",
    "\n",
    "config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emb_7def3fe8a51080e1466350a510a87a0b32d170dcda85c5fa'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = config['key']\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.90s/it]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "#Set up HuggingFace Pipeline with Llama-2-7b-chat-hf model\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "      \"text-generation\", #task\n",
    "      model=model,\n",
    "      tokenizer=tokenizer,\n",
    "      torch_dtype=torch.float16,\n",
    "      trust_remote_code=True,\n",
    "      device_map=\"auto\",\n",
    "      max_length=1000,\n",
    "      do_sample=True,\n",
    "      top_k=10,\n",
    "      num_return_sequences=1,\n",
    "      eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "#LLM intialized in HuggingFace Pipeline wrapper\n",
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Question: What types of fragrances do you offer?\\nAnswer: We sell exotic Indian fragrances.', metadata={'source': 'data/atcs-final-test.csv', 'row': 0})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = CSVLoader('data/atcs-final-test.csv')\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Question: What types of fragrances do you offer?\\nAnswer: We sell exotic Indian fragrances.' metadata={'source': 'data/atcs-final-test.csv', 'row': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Question: What types of fragrances do you offer?\\nAnswer: We sell exotic Indian fragrances.', metadata={'source': 'data/atcs-final-test.csv', 'row': 0}),\n",
       " Document(page_content='Question: Do you sell anything besides perfume?\\nAnswer: Yes! Incense, burning oils, etc.', metadata={'source': 'data/atcs-final-test.csv', 'row': 1})]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split document into text chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "print(docs[0])\n",
    "docs[0] = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding model\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.9/site-packages (0.6.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.9/site-packages (from tiktoken) (2024.4.16)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.9/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Collecting mixedbread-ai\n",
      "  Downloading mixedbread_ai-2.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in ./.venv/lib/python3.9/site-packages (from mixedbread-ai) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in ./.venv/lib/python3.9/site-packages (from mixedbread-ai) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in ./.venv/lib/python3.9/site-packages (from mixedbread-ai) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.20240311 (from mixedbread-ai)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in ./.venv/lib/python3.9/site-packages (from mixedbread-ai) (4.11.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.9/site-packages (from httpx>=0.21.2->mixedbread-ai) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx>=0.21.2->mixedbread-ai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx>=0.21.2->mixedbread-ai) (1.0.5)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.9/site-packages (from httpx>=0.21.2->mixedbread-ai) (3.7)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from httpx>=0.21.2->mixedbread-ai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.21.2->mixedbread-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.9.2->mixedbread-ai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.9.2->mixedbread-ai) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->mixedbread-ai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->mixedbread-ai) (2.2.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio->httpx>=0.21.2->mixedbread-ai) (1.2.1)\n",
      "Downloading mixedbread_ai-2.2.0-py3-none-any.whl (39 kB)\n",
      "Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, mixedbread-ai\n",
      "Successfully installed mixedbread-ai-2.2.0 types-requests-2.31.0.20240406\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken\n",
    "!pip install mixedbread-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ONNXMiniLM_L6_V2' object has no attribute 'embed_documents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/codykletter/ATCS/essay-annihilator/llm.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load it into ChromaDB\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m db \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(docs, default_ef)\n",
      "File \u001b[0;32m~/ATCS/essay-annihilator/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    777\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 778\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    779\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    780\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    781\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    782\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    783\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    784\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    785\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[1;32m    786\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[1;32m    787\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[1;32m    788\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    789\u001b[0m )\n",
      "File \u001b[0;32m~/ATCS/essay-annihilator/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatch_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_batches\n\u001b[1;32m    730\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m create_batches(\n\u001b[1;32m    731\u001b[0m         api\u001b[39m=\u001b[39mchroma_collection\u001b[39m.\u001b[39m_client,\n\u001b[1;32m    732\u001b[0m         ids\u001b[39m=\u001b[39mids,\n\u001b[1;32m    733\u001b[0m         metadatas\u001b[39m=\u001b[39mmetadatas,\n\u001b[1;32m    734\u001b[0m         documents\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    735\u001b[0m     ):\n\u001b[0;32m--> 736\u001b[0m         chroma_collection\u001b[39m.\u001b[39;49madd_texts(\n\u001b[1;32m    737\u001b[0m             texts\u001b[39m=\u001b[39;49mbatch[\u001b[39m3\u001b[39;49m] \u001b[39mif\u001b[39;49;00m batch[\u001b[39m3\u001b[39;49m] \u001b[39melse\u001b[39;49;00m [],\n\u001b[1;32m    738\u001b[0m             metadatas\u001b[39m=\u001b[39;49mbatch[\u001b[39m2\u001b[39;49m] \u001b[39mif\u001b[39;49;00m batch[\u001b[39m2\u001b[39;49m] \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    739\u001b[0m             ids\u001b[39m=\u001b[39;49mbatch[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    742\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n",
      "File \u001b[0;32m~/ATCS/essay-annihilator/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n\u001b[1;32m    277\u001b[0m     \u001b[39m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[39m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     length_diff \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(metadatas)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ONNXMiniLM_L6_V2' object has no attribute 'embed_documents'"
     ]
    }
   ],
   "source": [
    "# Load it into ChromaDB\n",
    "db = Chroma.from_documents(docs, default_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design Prompt Template\n",
    "template = \"\"\"You are an english teacher chatbot for an AP English language class.\n",
    "\n",
    "{context}\n",
    "\n",
    "Look for the phrases described in the source data. Surround these phrases with a double asterisk in the original text, and return it. If you are unsure, say \"I am unsure.\"\n",
    "\n",
    "Question:\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an english teacher chatbot for an AP English language class.\n",
      "\n",
      "A student has an essay they would like you to review\n",
      "\n",
      "Look for the phrases described in the source data. Surround these phrases with a double asterisk in the original text, and return it. If you are unsure, say \"I am unsure.\"\n",
      "\n",
      "Question:\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "#Intiliaze prompt using prompt template via langchain\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\"])\n",
    "print(\n",
    "    prompt.format(\n",
    "        context = \"A student has an essay they would like you to review\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'as_retriever'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/codykletter/ATCS/essay-annihilator/llm.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Chain to have all components together and query the LLM\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m chain_type_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m: prompt}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m chain \u001b[39m=\u001b[39m RetrievalQA\u001b[39m.\u001b[39mfrom_chain_type(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     llm\u001b[39m=\u001b[39mllm,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     retriever\u001b[39m=\u001b[39mdb\u001b[39m.\u001b[39;49mas_retriever(search_kwargs\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mk\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m}),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     chain_type_kwargs\u001b[39m=\u001b[39mchain_type_kwargs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/codykletter/ATCS/essay-annihilator/llm.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'as_retriever'"
     ]
    }
   ],
   "source": [
    "#Chain to have all components together and query the LLM\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted printing\n",
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=80)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running chain through LLM with query\n",
    "query = \"Does this text contain 'Since the beginning of time' Text: Since the beginning of time, humans have engaged in the practice of storytelling.\"\n",
    "response = chain.run(query)\n",
    "print_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
